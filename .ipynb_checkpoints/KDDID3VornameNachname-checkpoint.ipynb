{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree mit ID3\n",
    "Implementieren Sie den Decision-Tree-Algorithmus ID3 mit dem gegebenen Grundgerüst. Beachten Sie für Ihre Bearbeitung bitte die folgenden Punkte:\n",
    "- Bitte verwenden Sie in dieser Aufgabe die **Jupyter Notebook** Oberfläche und **nicht Jupyter Lab**. Ansonsten führt die Zeile ``%matplotlib notebook`` zu einem Fehler und muss durch ``%matplotlib inlne`` ersetzt werden. Dann ist jedoch kein vernünftiges Zoomen in die Bilder der Entscheidungsbäume innerhalb der Jupyter Oberfläche mehr möglich.\n",
    "- Verwenden Sie den Datensatz *house-votes-84-with-header.csv*, den Sie zusammen mit einer kurzen Beschreibung im Moodle finden.\n",
    "- Nicht jeder Record dieses Datensatzes hat für jedes Attribut einen Wert (mit *?* gekennzeichnet). Implementieren Sie daher Ihren ID3 Algorithmus so, dass er trotzdem eine sinnvolle Zuteilung trifft. Nähere Details dazu entnehmen Sie bitte dem [Paper von Quinlan](https://link.springer.com/article/10.1023%2FA%3A1022643204877).\n",
    "- Im Paper wird vorgeschlagen nur aus einer Teilmenge der Trainingsdaten den Baum zu bilden, dem sogenannten \"Window\". Dieses soll dann iterativ vergrößert werden, bis alle nicht im Window befindlichen Daten vom durch das Window gebildeten Baum korrekt klassifiziert werden. Diese Nutzung des Windows brauch von Ihnen NICHT umgesetz werden. Bilden Sie den Entscheidungsbaum direkt mit den kompletten Trainingsdaten!\n",
    "- Die in Abschnitt 5 beschriebene Behandlung von Rauschen sowie die in Abschnitt 7 vorgestellten Verbesserungen sollen Sie nicht umsetzen.\n",
    "- **Abgabe bis zum 17.01.2022 23:59 Uhr.** Sie werden uns Ihren Algorithmus kurz vorführen, erklären und ggf. Fragen beantworten.\n",
    "\n",
    "### Darstellung des Baumes\n",
    "- Dieses mal ist das Ergebnis ein Baum. Damit Sie sich nicht mit der Darstellung aufhalten, finden sie im gegebenen Grundgerüst eine Methode, die den Baum darstellt.\n",
    "- Bitte fügen Sie Ihrer Implementierung eine Methode hinzu, die den Baum als Dictionary repräsentiert. Das Dictionary für einen (Teil-)baum hat jeweils zwei Einträge:\n",
    "    - Ein Eintrag *'node_name'* bildet auf den Namen des Knotens ab (das zu testende Attribut oder bei Blättern die Klassenentscheidung).\n",
    "    - Ein Eintrag *'children'* bildet auf ein weiteres Dictionary ab. Dieses Dictionary enthält für jeden zu testenden Attributswert einen Eintrag, der auf den darunterliegenden Teilbaum abbildet.\n",
    "    - Handelt es sich beim aktuellen Knoten um ein Blatt, so gibt es keinen *'children'*-Eintrag.\n",
    "    - Bitte stellen Sie sicher, dass alle Einträge Strings sind.\n",
    "- Um Entscheidungsbäume zu plotten benötigen Sie das package [pydot](https://pypi.python.org/pypi/pydot) und die Software [GraphViz](http://www.graphviz.org/). Sie müssen außerdem den 'bin'-Unterordner im Installationspfad von GraphViz zur *Path*-Umgebungsvariable hinzufügen. Bei Problemen mit der Installation melden sie sich bitte bei <stubbemann@cs.uni-kassel.de>.\n",
    "\n",
    "### Verwendung der Bibliothek *pandas*\n",
    "In dieser Aufgabe verwenden wir die Bibliothek *pandas*. Die zentrale Funktion dieser Bibliothek ist die Repräsentation und Manipulation von Datensätzen in sogenannten *DataFrames* analog zur Programmiersprache *R*. Ein DataFrame kann man sich wie eine Tabelle vorstellen, die pro Zeile eine Instanz des Datensatzes enthält. Die nach den Attributsnamen benannten Spalten der Tabelle enthalten die jeweiligen Attributswerte der Instanzen. Die Zeilen des DataFrames sind indiziert, typischerweise durch eine ID oder einen Timestamp. Eine Spalte eines DataFrames hat den Datentyp *Series* und enthält alle Indizes zusammen mit dem jeweiligen Spaltenwert sowie den Namen (das Attribut). Im folgenden laden wir den Datensatz für diese Aufgabe und zeigen ein paar Beispieloperationen. Falls Sie mehr Operationen kennenlernen möchten, lesen Sie den Artikel [10 Minutes to pandas](https://pandas.pydata.org/pandas-docs/stable/10min.html).\n",
    "\n",
    "### Zusätzliche Pakete\n",
    "Sie dürfen zusätzlich die Pakete *math*, *random* und *numpy* verwenden.\n",
    "\n",
    "### Erweiterungen für 6 ECTS\n",
    "Bearbeiten Sie die folgenden Aufgaben nur, wenn Sie 6 ECTS benötigen!\n",
    "- Implementieren Sie die Funktion \"classification\", welche den mittels train berechneten Decision Tree nutzt um die einzelnen Datenpunkte zu klassifizieren. Die Funktion soll eine Liste von Classlabels zurückgeben. Hier soll also der i-te Eintrag die Klassenentscheidung für den i-ten Datenpunkt darstellen.\n",
    "- Um die Klassifikation von mittels Entscheidungsbäumen zu verbessern wird in der Praxis häufig ein Ensemble von Entscheidungsbäumen verwendet. Dabei wird jeder jeder Baum in der Praxis nur auf einen Teil der Trainingsdaten und der Attribute trainiert.\n",
    "- Implementieren Sie die Funktion **ensemble**, welche auf Trainingsdaten *d_train* *n_trees* viele Bäume trainiert, welche jeweils einen Anteil von *data_ratio* Datenpunkten und *attributes_ratio* viele Attribute pro Baum zufällig auswählen. Dabei soll jeweils aufgerundet werden. Die Ergebnisliste soll für jeden Datenpunkt in *d_test* jeweils ein Dictionary zurückgeben, welches für jede Klasse die Wahrscheinlichkeit entält.\n",
    "- Beispiel: Wir haben die Klassen \"A\" und \"B\" und wählen *data_ratio*=*attributes_ratio*=0.7 und *n_trees*=10. Dann sollen 10 Bäume mit jeweil 70% der Trainingsdaten und Attrbiute trainiert werden. Diese sollen jeweils zufällig gewählt werden. Taucht in der Ergebnisliste an 3.Stelle das Dictionary {\"A\": 0.7, \"B\": 0.3} auf, heißt dass, das der dritte Datenpunkt in den Trainingsdaten zu 70% zu Klasse \"A\" gehört, weil 7 von 10 Bäumen ihn so klassifizert haben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from a csv-file.\n",
    "df = pd.read_csv('house-votes-84-with-header.csv')\n",
    "\n",
    "# Show the first n elements of the data-frame with optional parameter n (default n=5). \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show number of rows (instances) and colums (attributes) of the data-set.\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a column.\n",
    "labels = df['class']\n",
    "\n",
    "# Get the unique values of a column. Returns a numpy array.\n",
    "labels.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the subset of the data for which an attribute/a column has a given value. Returns a data-frame. \n",
    "df_democrats = df.loc[df['class'] == 'democrat']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementierung des Entscheidungsbaums\n",
    "In diesem Teil implementieren Sie den ID3-Algorithmus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import ceil # To round up\n",
    "import random # For sampling etc.\n",
    "\n",
    "class DecisionTree():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.children = []\n",
    "        self.att_missing_val = '?'\n",
    "        self.att_class = 'class'\n",
    "        self.is_leaf = False\n",
    "        # TODO Here you can also change class properties, if you do not need them.\n",
    "    \n",
    "    def train(self, data):\n",
    "        \"\"\" Trains this classifier on a given pandas DataFrame.\n",
    "        The data has categorical attributes and one binary class-attribute (i.e. there exist two classes).\"\"\"\n",
    "        \n",
    "        unique_classes = data[self.att_class].unique()\n",
    "        n_classes = len(unique_classes)\n",
    "        assert(n_classes in {1,2})\n",
    "        \n",
    "        # TODO\n",
    "    \n",
    "    def to_dictionary(self):\n",
    "        # TODO\n",
    "    \n",
    "#######Everything under this line is only needed for 6ECTS. Remove it if you just need 3ECTS!######    \n",
    "    def classification(self, data):\n",
    "        \"\"\"\n",
    "        Uses the trained Decision tree to classify all data points of the given DataFrame.\n",
    "        The data has categorical attributes and one binary class-attribute (i.e. there exist two classes).\n",
    "        \"\"\"\n",
    "        # TODO\n",
    "        pass\n",
    "\n",
    "def ensemble(d_train,\n",
    "             d_test,\n",
    "             n_trees=10,\n",
    "             data_ratio=0.7,\n",
    "             attributes_ratio=0.7):\n",
    "    \"\"\"\n",
    "    Train n_trees for classification, where every tree just uses a sample of the training data\n",
    "    and the attributes.\n",
    "    \"\"\"\n",
    "  # TODO\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ausführung Ihres Algorithmus\n",
    "Ab hier bitte nichts mehr ändern. Die Datei *plot_tree.py* enthält neben der Methode zum Plotten auch ein Beispiel für die erwartete Datenstruktur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot_tree import plot_tree, example_tree_dict\n",
    "%matplotlib notebook\n",
    "\n",
    "# If you remove the comment symbol, you can test whether you've installed graphviz and pydot correctly.\n",
    "# plot_tree(example_tree_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTree()\n",
    "tree.train(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tree(tree.to_dictionary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ausführung auf alternativem Datensatz\n",
    "Hier können Sie Ihre Implementierung auf einem weiteren Datensatz testen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('id3-test.csv', header=None)\n",
    "df2.rename(columns={0: 'class', 1: 'outlook', 2: 'temperature', 3: 'humidity', 4: 'windy'}, inplace='True')\n",
    "df2 = df2.applymap(str)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree2 = DecisionTree()\n",
    "tree2.train(df2)\n",
    "plot_tree(tree2.to_dictionary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test for 6 ECTS \n",
    "Remove if you just need 3ECTS!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(predictions, targets):\n",
    "    \"\"\" Returns a tuple (labels, m) where m is the confusion matrix and \n",
    "    labels is the list of matrix rows/columns in same order as in the matrix.\n",
    "    Rows in the confusion matrix indicate the true target label\n",
    "    whereas the columns indicate the predicted label of samples. \"\"\"\n",
    "    assert(len(predictions) == len(targets))\n",
    "    \n",
    "    # Map each label to an index.\n",
    "    unique_vals = list(set(predictions).union(targets))\n",
    "    mapping = {label: index for index, label in enumerate(unique_vals)}\n",
    "    \n",
    "    # Build and fill the confusion matrix.\n",
    "    m = [[0]*len(mapping) for _ in range(len(mapping))]\n",
    "    for p, t in zip(predictions, targets):\n",
    "        row, col = mapping[t], mapping[p]\n",
    "        m[row][col] += 1\n",
    "    return unique_vals, m\n",
    "\n",
    "def accuracy(predictions, targets):\n",
    "    \"\"\" Calculates the accuracy for the given class predictions and true classes.\"\"\"\n",
    "    assert(len(predictions) == len(targets))\n",
    "    n_correct = len([p for p,t in zip(predictions, targets) if p==t])\n",
    "    return n_correct/len(predictions)\n",
    "\n",
    "def split_data(df,\n",
    "              test_size,\n",
    "              random_state):\n",
    "    #Shuffle data\n",
    "    df = df.sample(frac=1,\n",
    "                   random_state=random_state)\n",
    "    # Split data\n",
    "    k = ceil(len(df)*test_size)\n",
    "    return df[:k], df[k:]\n",
    "\n",
    "# Do train test split\n",
    "d_train, d_test = split_data(df, test_size=0.5, random_state=42)\n",
    "tree = DecisionTree()\n",
    "tree.train(d_train)\n",
    "labels = list(d_test[\"class\"])\n",
    "results = tree.classification(d_test)\n",
    "classes, matrix = confusion_matrix(results, labels)\n",
    "accuracy_score = accuracy(labels, results)\n",
    "print('Confusion matrix:')\n",
    "print(classes)\n",
    "for row in matrix:\n",
    "    print(row)\n",
    "print('----------')\n",
    "print(\"Accuracy: \", accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ensemble(d_train, d_test)\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
