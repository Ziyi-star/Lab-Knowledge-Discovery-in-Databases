{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering durch Varianzminimierung\n",
    "Implementieren Sie den Algorithmus *Clustering durch Varianzminimierung* innerhalb des jupyter-Notebooks. Nutzen Sie daf칲r das gegebene Grundger칲st und beachten Sie die folgenden Anforderungen:\n",
    "- Die initiale Clusterung soll auf folgende Art geschehen: Die ersten $k$ Elemente des Datensatzes werden auf die $k$ Cluster verteilt.\n",
    "Die restlichen Datenpunkte sollen zuf칛llig den Clustern zugeordnet werden. Dann werden die initialen Zentroide berechnet.\n",
    "- Als Distanzfunktion nutzen Sie bitte die Manhattan-Distanz.\n",
    "- In jedem Iterationsschritt soll der Algorithmus 칲ber alle Instanzen gehen und jede Instanz dem n칛chsten Centroid zuweisen. Nachdem alle Instanzen zugeordnet wurden, sollen die Zentroide neu berechnet werden.\n",
    "- Es gibt zwei Abbruchbedingungen:\n",
    "    1. Eine maximale Anzahl von Iterationen darf nicht 칲berschritten werden.\n",
    "    2. Unterschreitet die 츿nderung des Wertes\n",
    "        $${TD}^2(\\mathcal{C}) := \\sum_{i=1}^{k}{{TD}^2(C_i)} \\quad\\text{mit}\\quad {TD}^2(C_i) = \\sum_{p \\in C_i}{{dist}^2(p, \\mu_{C_i})}$$\n",
    "    zwischen zwei Iterationen ein gegebenes Minimum, dann wird keine neue Iteration mehr durchgef칲hrt.\n",
    "    \n",
    "  Die entsprechenden Grenzen werden als Parameter 칲bergeben. Der Wert ${TD}^2(\\mathcal{C})$ misst den Abstand aller Punkte zu ihren jeweiligen Centroiden $\\mu_{C_i}$ und ist ein Ma f칲r die Kompaktheit des Clusterings.\n",
    "- Die Modellierung der Centroide erfolgt in der Klasse *Cluster* als Liste numerischer Werte.\n",
    "- Die Klassen k칬nnen um weitere Methoden erg칛nzt werden.\n",
    "- Sie d칲rfen die Pakete numpy und random f칲r Ihre Implementierung nutzen. Au른rdem werden f칲r die Tests die Pakete pandas und matplotlib genutzt. Verwenden Sie keine weiteren Pakete f칲r Ihre Implementierung.\n",
    "- Beim Test auf einem geeigneten Datensatz soll ein sinnvolles Clustering entstehen.\n",
    "- Mit Hilfe des *print*-Kommandos werden Zwischenergebnisse jeder Clustering-Iteration sinnvoll geloggt.\n",
    "- Ihr Programmcode sollte sinnvoll kommentiert sein und sinnvolle Variablennamen verwenden.\n",
    "- *Hinweis*: Stellen Sie sicher, dass der Algorithmus bei jeder Ausf칲hrung ohne Fehler funktioniert. \n",
    "\n",
    "칖berlegen Sie sich, warum das nur unter Ber칲cksichtigung des Grundalgorithmus aus der Vorlesung auch mit den selben Parameterwerten nicht jedes mal der Fall sein muss und wie Sie dagegen vorgehen k칬nnen.\n",
    "\n",
    "- Ihre Implementierung k칬nnen Sie bis zum 28.11.2022 23:59 im Moodle abgeben.\n",
    "Sollten Sie Fragen zu den Aufgaben haben, wenden Sie sich bitte pers칬nlich oder per E-Mail an [Maximilian Stubbemann](mailto:stubbemann@cs.uni-kassel.de).\n",
    "\n",
    "## Zusatzaufgabe f칲r 6 ECTS:\n",
    "**Hinweis**: Bearbeiten Sie diese Aufgabe nur, falls Sie am Praktikum f칲r 6 ECTS-Punkte teilnehmen, jedoch nicht, falls Sie am Praktikum f칲r 3 ECTS-Punkte teilnehmen.\n",
    "\n",
    "Das Ziel des folgenden Algorithmus ist es, das Clustering durch Varianzminimierung zu verbessern, indem bessere Startcluster gew칛hlt werden. Der Algorithmus geht dabei wie folgt vor:\n",
    "1. Es wird ein Datenpunkt zuf칛llig (gleichverteilt) als erster Zentrumspunkt gew칛hlt.\n",
    "2. F칲r jeden Datenpunkt $x$, welcher noch kein Zentroid ist, wird $D(x)$ als die Distanz zwischen x und dem n칛hesten Zentrumspunkt zu $x$ berechnet.\n",
    "3. Es wird ein weiterer Zentrumspunkt mit einer gewichteten Wahrscheinlickeitsverteilung gew칛hlt, wobei der Punkt $x$ mit einer Wahrscheinlichkeit proportional zu $D(x)^2$ gew칛hlt wird.\n",
    "4. Die Schritte 2 und 3 werden wiederholt, bis $k$ Zentrumspunkte gew칛hlt wurden.\n",
    "5. Mit den $k$ Zentrumspunkte als Startpunkten wird dann ein Clustering durch Varianzminimierung durchgef칲hrt.\n",
    "\n",
    "Modifizieren Sie Ihren Code so, dass beim Aufruf durch einen Parameter **init** ausgew칛hlt werden kann, ob der optimierte Initialisierungsalgorithmus verwendet werden soll.\n",
    "\n",
    "## Tipps:\n",
    "- Zum Debugging kann es hilfreich sein, sich w칛hrend der Implementierung einzelne Variablenwerte ausgeben zu lassen, insbesondere wenn Sie sich nicht sicher sind, welchen Variablentypen oder Wert Ihre Variable hat oder wenn f칲r Sie unerkl칛rliche Fehler auftreten. Entweder verwenden Sie zur Ausgabe einfach das *print*-Kommando oder erstellen eine Zelle, in die Sie den Variablennamen als letzte Anweisung schreiben und ausf칲hren.\n",
    "- Neben dem Ausprobieren verschiedener Parameterwerte um ein besseres Verst칛ndnis f칲r den Algorithmus zu bekommen, kann es auch sinnvoll sein, Ihre Implementierung mehrfach mit den selben Werten auszuf칲hren.\n",
    "- Sie k칬nnen (m칲ssen aber nicht) einfache numpy-Operationen verwenden. Vektoren als Methodenparameter, R칲ckgabewerte oder Klasseneigenschaften sollen aber als normale Python-Listen dargestellt werden, *nicht* als numpy-Arrays. Aus dem Code und bei der Vorstellung Ihrer Implementierung sollte au른rdem ersichtlich sein, dass Sie selbst die Berechnungen per Hand durchf칲hren k칬nnten. Dies gilt insbesondere f칲r das Distanzma. \n",
    "- Jeglicher Python-Code im Jupyter-Notebook wird in der Reihenfolge ausgef칲hrt, in der die Zellen ausgef칲hrt wurden. Alle zugewiesenen Namen (z. Bsp. f칲r Variablen, Funktionen und Klassen) bleiben im Speicher erhalten, sofern Sie nicht 칲berschrieben wurden. Um einen *frischen* Zustand zu erhalten, in dem noch kein Code ausgef칲hrt wurde, gehen Sie auf *Kernel -> Restart & Clear Output*. Falls f칲r Sie unerkl칛rliche Fehler auftreten oder Fehler, die Sie glauben schon behoben zu haben, kann ein Kernel Restart oft Erkenntnisse liefern. In vielen F칛llen greifen Sie noch auf Programmcode zu, den Sie bereits aus den Zellen gel칬scht haben. Stellen Sie vor der Abgabe sicher, dass Ihr Notebook auch in der Reihenfolge der Zellen von oben nach unten ohne Fehler durchl칛uft (Kernel -> Restart & Run All)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def manhattan_dist(x, y):\n",
    "    \"\"\" Returns the manhattan distance between vectors x and y.\n",
    "    A vector is represented as a list of numeric values. \"\"\"\n",
    "    assert(len(x) == len(y))\n",
    "    \n",
    "    # Ansatz: zip gibt eine List von 2 Elemente\n",
    "    distance = 0\n",
    "    for x_i,y_i in zip(x,y):\n",
    "        distance += abs(x_i - y_i)\n",
    "    return distance\n",
    "   \n",
    "\n",
    "class VarMinClusterer():\n",
    "    def __init__(self, dist_fun=manhattan_dist):\n",
    "        self.dist_fun = dist_fun\n",
    "        self.clusters = []\n",
    "    \n",
    "    def cluster(self,\n",
    "                X,\n",
    "                k=3,\n",
    "                max_iterations=20,\n",
    "                min_compactness_diff=0.05,\n",
    "                init=False):\n",
    "        \"\"\" Cluster the given data X.\n",
    "        Takes a list of samples X where each sample is a list of numeric values.\n",
    "        The parameter init determines, whether the optimized initialization procedure\n",
    "        shoud be used. If you are doing the task for 3 ECTS, this parameter should not\n",
    "        affect your code at all.\"\"\"\n",
    "        \n",
    "        # Basic parameter validation.\n",
    "        assert(len(X) > 0)\n",
    "        assert(len(X) >= k)\n",
    "        assert(max_iterations > 0)\n",
    "        \n",
    "        self.clusters = [Cluster() for i in range(k)]\n",
    "        \n",
    "        #1. Aufgabe ohne Optimierung\n",
    "        if init == False:\n",
    "        #initial\n",
    "            #1.erste k punte in jeweilige Cluster zuordnen\n",
    "            for i in range(k):\n",
    "                self.clusters[i].centroid = X[i]\n",
    "                self.clusters[i].elements.append(X[i])\n",
    "            #2.Die restlichen Datenpunkte sollen zuf칛llig den Clustern zugeordnet werden. \n",
    "            for i in range(k-1,len(X)):\n",
    "                randomNumber = random.randint(0,k-1)\n",
    "                self.clusters[randomNumber].elements.append(X[i])\n",
    "                \n",
    "        if init == True:\n",
    "            #1. Es wird ein Datenpunkt zuf칛llig (gleichverteilt) als erster Zentrumspunkt gew칛hlt.\n",
    "            centroidListIndex = []\n",
    "            XNew = X.copy()\n",
    "            randomNumber = random.randint(0,len(X))\n",
    "            self.clusters[k-1].centroid = X[randomNumber]\n",
    "            self.clusters[k-1].elements.append(X[randomNumber])\n",
    "            XNew.pop(randomNumber)\n",
    "            centroidListIndex.append(randomNumber)\n",
    "            k -= 1\n",
    "            #F칲r jeden Datenpunkt 洧논, welcher noch kein Zentroid ist, \n",
    "            #wird 洧냥(洧논) als die Distanz zwischen x und dem n칛hesten Zentrumspunkt zu 洧논 berechnet.\n",
    "            while k != 0:\n",
    "                distanceCentroidPunct = []\n",
    "                for i in range(len(XNew)):\n",
    "                    distanceCentroidPunctElementQuadrat = manhattan_dist(X[randomNumber],XNew[i]) **2\n",
    "                    distanceCentroidPunct.append(distanceCentroidPunctElementQuadrat)\n",
    "    #Es wird ein weiterer Zentrumspunkt mit einer gewichteten Wahrscheinlickeitsverteilung gew칛hlt, \n",
    "    #wobei der Punkt 洧논 mit einer Wahrscheinlichkeit proportional zu 洧냥(洧논)2 gew칛hlt wird.     \n",
    "                for i in range(len(XNew)):\n",
    "                    if distanceCentroidPunct[i] == max(distanceCentroidPunct):\n",
    "                        #print(\"max:\" + str(max(distanceCentroidPunct))\n",
    "                        self.clusters[k-1].centroid = XNew[i]\n",
    "                        self.clusters[k-1].elements.append(XNew[i])\n",
    "                        centroidListIndex.append(i)\n",
    "                        XNew.pop(i)\n",
    "                        k -= 1\n",
    "                        break\n",
    "            #elements in Cluster zu ordnen mit Zufall\n",
    "            print(centroidListIndex)\n",
    "            for i in range(len(XNew)):\n",
    "                randomNumber = random.randint(0,2)\n",
    "                #if the element is not the current center\n",
    "                self.clusters[randomNumber].elements.append(XNew[i])\n",
    "                 \n",
    "        #berechen Algothmus von Vorlesung\n",
    "        while max_iterations != 0 or min_compactness_diff >= 0.05:\n",
    "            centroidenList = []\n",
    "            #풮C0 = 풮C;\n",
    "            compactnessOldClusters = 0\n",
    "            for cluster in self.clusters:\n",
    "                centroidenList.append(cluster.centroid)\n",
    "                 # old elements in jede Cluster leeren\n",
    "                cluster.elements = []\n",
    "                #calculate compactness for the old cluster \n",
    "                compactnessOldClusters = compactnessOldClusters + cluster.compactness()\n",
    "                \n",
    "            #jede Punkt eine neue Cluster zuordnen\n",
    "            for point in X:\n",
    "                newClusterCalculate = []\n",
    "                #jede Punkte in Cluster , berechnen mal die manhattan_dist, werden der Punkte zu der Kleinste Wert geordnet.\n",
    "                for centroide in centroidenList:\n",
    "                    newClusterCalculate.append(manhattan_dist(point, centroide))\n",
    "                minDistance = min(newClusterCalculate)\n",
    "                min_index=newClusterCalculate.index(minDistance)\n",
    "                self.clusters[min_index].elements.append(point)\n",
    "                \n",
    "            #td fuer ganze clusters berechnen\n",
    "            compactnessNewClusters = 0\n",
    "            for cluster in self.clusters:\n",
    "                cluster.calculateCentroide()\n",
    "                compactnessNewClusters = compactnessNewClusters + cluster.compactness()\n",
    "        \n",
    "            max_iterations -=1\n",
    "            min_compactness_diff = abs(compactnessOldClusters-compactnessNewClusters)\n",
    "                \n",
    "        return self.clusters\n",
    "\n",
    "class Cluster():\n",
    "    def __init__(self):\n",
    "        self.elements = []\n",
    "        self.centroid = []\n",
    "    \n",
    "    def compactness(self, dist_fun=manhattan_dist):\n",
    "        # TODO\n",
    "        #Die entsprechenden Grenzen werden als Parameter 칲bergeben. \n",
    "        sum = 0\n",
    "        for x in self.elements:\n",
    "          sum = sum + manhattan_dist(self.centroid,x)**2\n",
    "        return sum\n",
    "    \n",
    "    def calculateCentroide(self,dist_fun=manhattan_dist):\n",
    "        elementsNP = np.array(self.elements)\n",
    "        #Mittelwert fur alle Elements\n",
    "        center = np.mean(elementsNP, axis=0)\n",
    "        #die nahliegendeste Punkt zu suchen\n",
    "        newCenterTempList = []\n",
    "        for point in self.elements:\n",
    "            newCenterTempList.append(manhattan_dist(center,point))\n",
    "        minDistance = min(newCenterTempList)\n",
    "        min_index=newCenterTempList.index(minDistance)\n",
    "        self.centroid = self.elements[min_index]\n",
    "        return self.centroid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ausf칲hrung des Clusterings\n",
    "Hier kann der implementierte Algorithmus getestet werden. Bitte an den vorhandenen Zellen nichts 칛ndern. Sie k칬nnen aber weitere Zellen mit eigenem Code hinzuf칲gen oder andere Parameterwerte ausprobieren (die Sie in der Abgabe dann wieder auf die urspr칲nglichen Werte 칛ndern).\n",
    "\n",
    "Um den Code auszuf칲hren, m칲ssen die Bibliotheken *pandas*, *matplotlib* und eventuell weitere Abh칛ngigkeiten installiert sein. Diese sind in der Anaconda-Distribution bereits enthalten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the iris-dataset. Remove the class-attribute.\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"iris.csv\")\n",
    "del data[\"species\"]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clustering(clusters, x_dim=0, y_dim=3):\n",
    "    \"\"\"Show a scatterplot of the given clusters and contained data-points.\n",
    "    Points from the same cluster will have the same color.\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    plt.figure()\n",
    "    for cluster in clusters:\n",
    "        elems = np.array(cluster.elements)\n",
    "        plt.scatter(elems[:, x_dim], elems[:, y_dim])\n",
    "        ctr = cluster.centroid\n",
    "        plt.plot(ctr[x_dim], ctr[y_dim], \"X\", c=\"black\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a clustering with k=3 and plot the result with the optimized initialization routine.\n",
    "# This code should run and (always) show a correct result, once the classes have been implemented.\n",
    "alg = VarMinClusterer()\n",
    "clusters = alg.cluster(data.values.tolist(), k=3, init=True)\n",
    "plot_clustering(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a clustering with k=3 and plot the result.\n",
    "# This code should run and (always) show a correct result, once the classes have been implemented.\n",
    "alg = VarMinClusterer()\n",
    "clusters = alg.cluster(data.values.tolist(), k=3, init=False)\n",
    "plot_clustering(clusters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "7e1998ff7f8aa20ada591c520b972326324e5ea05489af9e422744c7c09f6dad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
