{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:85% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:85% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Klassifikation mit *k*-Nearest-Neighbors\n",
    "Ziel dieser Übung ist das eigenständige Implementieren des Klassifikations-Algorithmus *k*-Nearest-Neighbors innerhalb des Jupyter-Notebooks. Implementieren sie folgende Variante des *k*-Nearest-Neighbors:\n",
    "- Alle Attribute sind vor der Benutzung auf den Wertebereich $[0;1]$ zu normieren. Beachten Sie dabei, dass für das \"Training\" des Klassifikators keine Informationen aus den Testdaten verwendet werden dürfen.\n",
    "- Als Distanzfunktion nutzen Sie bitte die euklidische Distanz.\n",
    "- Für das Abstimmen der *k* nächsten Nachbarn soll es vier Varianten geben, die mittels eines Parameters an die Klasse übergeben werden können:\n",
    "    1. Eine einfache Mehrheitsabstimmung unter den Nachbarn\n",
    "    2. Jeder Nachbar wird mit dem inversen Quadrat der Distanz gewichtet.\n",
    "    3. Die Stimmen einer Klasse werden mit dem Inversen ihrer Durchschnittsdistanz gewichtet.\n",
    "    4. Eine Mehrheitsabstimmung gewichtet nach der Verteilung der Klassen.\n",
    "   \n",
    "Sie dürfen die Pakete **collections**, **math** und **numpy** für Ihre Implementierung nutzen. Für die Ausführung der Tests benötigen Sie außerdem **pandas**.\n",
    "\n",
    "# Aufgaben für 6ECTS\n",
    "Der *k*-nearest Neighbor Algorithmus verwendet für die Klassifikation verschiedene Parameter: Es muss ein fester Wert für **k** und eine der Entscheidungsstrategien gewählt werden. Doch wie wählt man die Parameter sinnvoll? Eine Möglichkeit liefert die Kreuzvalidierung, welche Sie implementieren sollen:\n",
    "Die Funktion *train* hat einen Parameter **ks**. Falls dieser nicht *None* ist, soll dieser Parameter genutzt werden, um eine Liste von Möglichen *k* Werten zu übergeben. Sie sollen dann wie folgt vorgehen, um aus diser Liste von *k* Werten das bestmögliche *k* und die bestmögliche der 4 Stragtegien zu wählen:\n",
    "- Teilen Sie die Daten zufällig in 5 gleichgroße Teile auf. Nutzen Sie dafür die vorgegbene Funktion *split*.\n",
    "- Gehen Sie für jedes Kombination für *k* und jeder Stratege *s* wie folgt vor um die besten Werte zu finden:\n",
    "- Für jede der 5 Datensatzteile \"trainieren\" sie auf den üblichen 4 Teilen und klassifizieren die Daten des nicht zum Training verwerndeten Teil. Zählen Sie die richtigen Klassifikationen.\n",
    "- Summieren Sie auf, sodass sie die richtigen Entscheidungen über alle 5 Teile erhalten.\n",
    "- Nun haben sie für jedes Paar (*k*,*s*) eine Anzahl an richtigen Entscheidungen über die 5 Teile.\n",
    "- Wählen Sie nun die beste Kombination aus und \"trainieren\" sie auf den ganzen Datensatz. Speichern Sie außerdem das \"beste\" Paar (*k*,*s*).\n",
    "- Wird nun die Funktion *predict* mit *best_combination=True* aufgerufen, so sollen der ermittelte Wert für *k* und die ermittelte Strategie statt die übergebenen Werte genutzt werden.\n",
    "\n",
    "\n",
    "Damit die Aufgabe als sinnvoll bearbeitet gilt, sind folgende Anforderungen zu erfüllen:\n",
    "- Bei einem Durchlauf durch den Iris-Datensatz sollen keine Ausführungsfehler bestehen und (sehr) gute Werte für die Accuracy geliefert werden.\n",
    "- Abgabe der Übung bis 06.02.2023 23:59 Uhr im Moodle-Kurs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import Counter, defaultdict\n",
    "import numpy as np\n",
    "import random # Just needed for 6ECTS\n",
    "\n",
    "\n",
    "def euclidean_dist(x, y):\n",
    "    # TODO\n",
    "    #prüfen ob die beiden Vektoren x und y die gleiche Dimension \n",
    "    assert len(x) == len(y)\n",
    "    #die Summe der quadrierten Differenzen berechnet \n",
    "    squared_dist = sum((xi - yi) ** 2 for xi, yi in zip(x, y))\n",
    "    return math.sqrt(squared_dist)\n",
    "\n",
    "def split(X, Y, n=5):\n",
    "    \"Split the training points and labels into 5 equal sized parts. Just needed for 6 ECTS.\"\n",
    "    m = list(range(len(X)))\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    indices = [np.array(m[i::n]) for i in range(n)]\n",
    "    X = [X[i].tolist() for i in indices]\n",
    "    Y = [Y[i].tolist() for i in indices]\n",
    "    return X, Y\n",
    "\n",
    "class KNN():\n",
    "    def __init__(self, dist_fun=euclidean_dist):\n",
    "        self.dist_fun = dist_fun\n",
    "        self.strategies = ['majority', 'inverse_squared_distance', 'inverse_avg_distance', 'distribution']\n",
    "        self.k = None\n",
    "        self.strategy = None\n",
    "        self.trainingDataWert = None\n",
    "        self.trainingDataLabel = None\n",
    "        self.dataMin = None\n",
    "        self.dataMax = None\n",
    "        \n",
    "    def train(self, X, Y, ks=None):\n",
    "        \"\"\" Train this classifier. Takes a list of samples X and a list of class-labels Y.\n",
    "        Each sample is a list of numeric values. Each label is a string.\n",
    "        The parameter ks ist just needed for 6ECTS.\"\"\"\n",
    "        #x die numerische Daten,y labels/Bezeichnung, was macht gibt zurück keine Ahnung\n",
    "        assert(len(X) == len(Y))\n",
    "        \n",
    "        # TODO\n",
    "        #auf den Wertebereich [0;1] zu normieren\n",
    "        data = np.array(X)\n",
    "        self.dataMin = np.min(data)\n",
    "        self.dataMax = np.max(data)\n",
    "        normalizedData = (data-np.min(data))/(np.max(data)-np.min(data))\n",
    "        if ks == None:\n",
    "            #dictionary erstellen mit label und nomierte Werte\n",
    "            self.trainingDataWert = normalizedData\n",
    "            self.trainingDataLabel = Y\n",
    "        if ks != None:\n",
    "            #todo\n",
    "            #Teilen Sie die Daten zufällig in 5 gleichgroße Teile auf, benutzen the split() oben\n",
    "            X_parts, Y_parts = split(normalizedData, Y, n=5)\n",
    "            best_correct = -1\n",
    "            best_k = -1\n",
    "            best_strategy = None\n",
    "            for s in self.strategies:\n",
    "                for kWert in ks:\n",
    "                    i = random.randint(0, 4)\n",
    "                    # Split the data into a training set and a test set\n",
    "                    self.trainingDataWert = np.concatenate([X_parts[j] for j in range(5) if j != i])\n",
    "                    self.trainingDataLabel = np.concatenate([Y_parts[j] for j in range(5) if j != i])\n",
    "                    X_test = X_parts[i]\n",
    "                    Y_test = Y_parts[i]        \n",
    "                    # Für jede der 5 Datensatzteile \"trainieren\" sie auf den üblichen 4 Teilen und \n",
    "                    #klassifizieren die Daten des nicht zum Training verwerndeten Teil. \n",
    "                    Y_pred = clf.predict(X_test, strategy=s, k=kWert)\n",
    "                    #Zählen Sie die richtigen Klassifikationen.\n",
    "                    # Summieren Sie auf, sodass sie die richtigen Entscheidungen über alle 5 Teile erhalten.\n",
    "                    #Listcompresion: eine Liste von 1 für jede richtige Klassifizierung, dann sum(), um alle 1s zu sumieren\n",
    "                    num_correct = sum([1 for i in range(len(Y_test)) if Y_pred[i] == Y_test[i]])\n",
    "                    # Nun haben sie für jedes Paar (k,s) eine Anzahl an richtigen Entscheidungen über die 5 Teile.\n",
    "                    if num_correct > best_correct:\n",
    "                        best_correct = num_correct\n",
    "                        best_k = kWert\n",
    "                        best_strategy = s\n",
    "            # Wählen Sie nun die beste Kombination aus und \"trainieren\" sie auf den ganzen Datensatz. Speichern Sie außerdem das \"beste\" Paar (k,s).\n",
    "            self.trainingDataWert = np.concatenate(X_parts)\n",
    "            self.trainingDataLabel = np.concatenate(Y_parts)\n",
    "            self.k = best_k\n",
    "            self.strategy = best_strategy\n",
    "        \n",
    "    def predict(self, X, k=3, strategy='majority', best_combination=False):\n",
    "        \"\"\" Takes a list of samples X. Returns a list of predicted labels for the samples.\n",
    "        The parameter best_combination ist just needed for 6ECTS.\"\"\"\n",
    "        if best_combination ==False:\n",
    "            return [self.predict_sample(x, k, strategy) for x in X]\n",
    "         # Wird nun die Funktion predict mit best_combination=True aufgerufen, \n",
    "        #so sollen der ermittelte Wert für k und die ermittelte Strategie statt die übergebenen Werte genutzt werden.\n",
    "        if best_combination ==True:\n",
    "            return [self.predict_sample(x, self.k, self.strategy) for x in X]\n",
    "        \n",
    "    \n",
    "    def predict_sample(self, x, k=3, strategy='majority'):\n",
    "        \"\"\" Predicts the label for a single sample x. \"\"\"\n",
    "        # TODO\n",
    "        #x normalisieren\n",
    "        xNormilized = (x-self.dataMin)/(self.dataMax-self.dataMin)\n",
    "        # für alle traing Data,  Abstand zwischen x und data berechnen, speichert in eine List für folgenden Fällen\n",
    "        distances = [(self.trainingDataLabel[i], self.dist_fun(self.trainingDataWert[i], xNormilized)) for i in range(len(self.trainingDataWert))]\n",
    "        distances.sort(key=lambda x:x[1])\n",
    "        #         print('distances')\n",
    "#         print(distances)\n",
    "        #Eine einfache Mehrheitsabstimmung unter den Nachbarn\n",
    "        if strategy == 'majority':\n",
    "            #Sortieren in aufsteigender Reihenfolge, basierend auf einem Abstandswert\n",
    "            #Ermitteln der ersten k Stichproben\n",
    "            neighbors = [distances[i][0] for i in range(k)]\n",
    "            prediction = max(neighbors,key=neighbors.count)\n",
    "            \n",
    "        # Jeder Nachbar wird mit dem inversen Quadrat der Distanz gewichtet.\n",
    "        if strategy == 'inverse_squared_distance':\n",
    "            neighbors = [(distances[i][0],distances[i][1]) for i in range(k)]\n",
    "            neighbor_counts = {}\n",
    "            for (neighbor,distance) in neighbors:\n",
    "                # die dict.get()-Methode verwendet, um die aktuelle Anzahl der einzelnen Nachbarn anzurufen, \n",
    "                #und standardmäßig 0, wenn der Nachbar nicht im Wörterbuch enthalten ist\n",
    "                if distance != 0: \n",
    "                    neighbor_counts[neighbor] = neighbor_counts.get(neighbor, 0) + 1/distance**2 \n",
    "            prediction = max(neighbor_counts, key=neighbor_counts.get)\n",
    "\n",
    "        #Die Stimmen einer Klasse werden mit dem Inversen ihrer Durchschnittsdistanz gewichtet.\n",
    "        if strategy == 'inverse_avg_distance':\n",
    "            unique_vals = set(self.trainingDataLabel)\n",
    "#             print('unique_vals')\n",
    "#             print(unique_vals)\n",
    "            neighbors = [(distances[i][0],distances[i][1]) for i in range(k)]\n",
    "            labelWithAverageDistance = {}\n",
    "            for label in unique_vals:\n",
    "                sumDistance = 0\n",
    "                count = 0\n",
    "                for (name, distance) in distances:\n",
    "                    if name == label:\n",
    "                        count += 1\n",
    "                        sumDistance += distance\n",
    "                labelWithAverageDistance[label] = sumDistance/count\n",
    "#             print('labelWithAverageDistance')\n",
    "#             print(labelWithAverageDistance)\n",
    "\n",
    "            neighbor_counts = {}\n",
    "            for (neighbor,distance) in neighbors:\n",
    "                neighbor_counts[neighbor] = neighbor_counts.get(neighbor, 0) + 1/labelWithAverageDistance[neighbor]\n",
    "            prediction = max(neighbor_counts, key=neighbor_counts.get)\n",
    "        \n",
    "#         # Eine Mehrheitsabstimmung gewichtet nach der Verteilung der Klassen.\n",
    "        if strategy == 'distribution':\n",
    "            counted_items = Counter(self.trainingDataLabel)\n",
    "            neighbors = [distances[i][0] for i in range(k)]\n",
    "            counted_items_neighbour = Counter(neighbors)\n",
    "            for item, count in counted_items_neighbour.items():\n",
    "                counted_items_neighbour[item] *= counted_items.get(item)\n",
    "            prediction = counted_items_neighbour.most_common(1)[0][0]\n",
    "            \n",
    "        return prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluierung des Klassifikators\n",
    "Mit diesem Code können Sie Ihre Implementierung anhand des mitgelieferten IRIS-Datensatzes testen. Probieren Sie auch verschiedene (sinnvolle) Werte für den Parameter *k*. Bitte ansonsten in diesem Teil nichts mehr ändern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, targets):\n",
    "    \"\"\" Calculates the accuracy for the given class predictions and true classes.\"\"\"\n",
    "    assert(len(predictions) == len(targets))\n",
    "    n_correct = len([p for p,t in zip(predictions, targets) if p==t])\n",
    "    return n_correct/len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(predictions, targets):\n",
    "    \"\"\" Returns a tuple (labels, m) where m is the confusion matrix and \n",
    "    labels is the list of matrix rows/columns in same order as in the matrix.\n",
    "    Rows in the confusion matrix indicate the true target label\n",
    "    whereas the columns indicate the predicted label of samples. \"\"\"\n",
    "    assert(len(predictions) == len(targets))\n",
    "    \n",
    "    # Map each label to an index.\n",
    "    #Return a set that contains all items from both sets, duplicates are excluded:\n",
    "    unique_vals = list(set(predictions).union(targets))\n",
    "    mapping = {label: index for index, label in enumerate(unique_vals)}\n",
    "    \n",
    "    # Build and fill the confusion matrix.\n",
    "    #??\n",
    "    m = [[0]*len(mapping) for _ in range(len(mapping))]\n",
    "    for p, t in zip(predictions, targets):\n",
    "        row, col = mapping[t], mapping[p]\n",
    "        #row ist target, col ist prediction mit indexanzahl \n",
    "        m[row][col] += 1\n",
    "    return unique_vals, m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the csv and drop duplicate entries.\n",
    "data = pd.read_csv('iris.csv').drop_duplicates()\n",
    "\n",
    "# Draw a random sample without replacement for the test data.\n",
    "test_data = data.sample(n=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The other samples are used as training data.\n",
    "train_data = data.loc[data.index.drop(test_data.index), :]\n",
    "\n",
    "def df_to_vectors(df):\n",
    "    \"\"\"Takes a pandas data-frame from the iris dataset as input.\n",
    "    Returns a tuple (X, Y) where Y is a list of class labels and X is the list of sample-vectors\n",
    "    with each vector represented as a list of numeric values.\"\"\"\n",
    "    df = df.copy()\n",
    "    classes = df['species']\n",
    "    del df['species']\n",
    "    return df.values.tolist(), classes.values.tolist()\n",
    "\n",
    "# Convert train and test-data to lists of vectors and class labels.\n",
    "X_train, Y_train = df_to_vectors(train_data)\n",
    "\n",
    "# print('X_train:')\n",
    "# print(X_train)\n",
    "# print('Y_train:')\n",
    "# print(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, Y_test = df_to_vectors(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of strategy majority: 0.94\n",
      "Confusion matrix:\n",
      "[15, 0, 0]\n",
      "[0, 18, 3]\n",
      "[0, 0, 14]\n",
      "----------\n",
      "Accuracy of strategy inverse_squared_distance: 0.94\n",
      "Confusion matrix:\n",
      "[15, 0, 0]\n",
      "[0, 18, 3]\n",
      "[0, 0, 14]\n",
      "----------\n",
      "Accuracy of strategy inverse_avg_distance: 0.94\n",
      "Confusion matrix:\n",
      "[15, 0, 0]\n",
      "[0, 18, 3]\n",
      "[0, 0, 14]\n",
      "----------\n",
      "Accuracy of strategy distribution: 0.94\n",
      "Confusion matrix:\n",
      "[15, 0, 0]\n",
      "[0, 18, 3]\n",
      "[0, 0, 14]\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "clf = KNN()\n",
    "clf.train(X_train, Y_train)\n",
    "for strategy in clf.strategies:\n",
    "    predictions = clf.predict(X_test, strategy=strategy, k=3)\n",
    "    print('Accuracy of strategy {}: {}'.format(strategy, accuracy(predictions, Y_test)))\n",
    "    labels, matrix = confusion_matrix(predictions, Y_test)\n",
    "    print('Confusion matrix:')\n",
    "    print('\\n'.join([str(row) for row in matrix]))\n",
    "    print('----------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete the following Lines if you just need 3 ECTS!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best combination:\n",
      "k: 3\n",
      "strategy: majority\n",
      "-----------\n",
      "Accuracy 0.92\n",
      "Confusion matrix:\n",
      "[15, 0, 0]\n",
      "[0, 17, 4]\n",
      "[0, 0, 14]\n"
     ]
    }
   ],
   "source": [
    "clf = KNN()\n",
    "clf.train(X_train, Y_train, ks=[1, 3, 5, 7])\n",
    "print(\"Best combination:\")\n",
    "print(\"k:\", clf.k)\n",
    "print(\"strategy:\", clf.strategy)\n",
    "print(\"-----------\")\n",
    "predictions = clf.predict(X_test, best_combination=True)\n",
    "labels, matrix = confusion_matrix(predictions, Y_test)\n",
    "print('Accuracy {}'.format(accuracy(predictions, Y_test)))\n",
    "print('Confusion matrix:')\n",
    "print('\\n'.join([str(row) for row in matrix]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
